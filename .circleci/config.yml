version: 2.1
aws_defaults: &aws_defaults
  AWS_ACCOUNT: "578681496768"
  ECR_REGION: "us-east-1"
  ECS_REGION: "us-west-1"

commands:
  notify:
    description: "Notifies the team with a message"
    parameters:
      msg:
        type: string
    steps:
      - run:
          name: Send message
          command: |
              # this is necessary to get the environment variables to interpolate properly
              echo "{\"text\":\"<< parameters.msg >>\"}" >parms.txt
              curl -X POST -H 'Content-type: application/json' --data @parms.txt https://hooks.slack.com/services/$SLACK_DEPLOYS_KEY

  notify_error:
    description: "Notifies the team with a message only when an error occurs"
    parameters:
      msg:
        type: string
    steps:
      - run:
          name: Send error message
          command: |
              echo "{\"text\":\"<< parameters.msg >>\"}" >parms.txt
              curl -X POST -H 'Content-type: application/json' --data @parms.txt https://hooks.slack.com/services/$SLACK_DEPLOYS_KEY
          when: on_fail

  mark_honeycomb:
    description: "Places a marker in the ci-deploy honeycomb dataset"
    parameters:
      msg:
        type: string
    steps:
      - run:
          name: Create honeycomb marker
          command: |
            echo "{\"message\":\"<< parameters.msg >>\", \"type\":\"deploy\"}" > parms.txt
            curl -X POST -H "X-Honeycomb-Team: $HONEYCOMB_KEY" -d @parms.txt "https://api.honeycomb.io/1/markers/$HONEYCOMB_DATASET"

  save_image:
    description: "Saves a docker image to the cache"
    parameters:
      img_name:
        type: string
      key:
        type: string
    steps:
      # bring back a cache if one already exists
      - restore_cache:
          key: << parameters.key >>
      - run:
          name: Save docker image to cache
          command: |
            # ensure cache directory
            [ -d /opt/docker-cache ] || mkdir -p /opt/docker-cache
            docker save -o "/opt/docker-cache/<< parameters.img_name >>.docker" "<< parameters.img_name >>"
      # saves this path with this cache key
      - save_cache:
          key: << parameters.key >>
          paths:
            - /opt/docker-cache

  restore_image:
    description: "Restores a docker image from the cache"
    parameters:
      img_name:
        type: string
      key:
        type: string
    steps:
      - restore_cache:
          key: << parameters.key >>
      - run:
          name: Load docker image from cache
          command: |
            docker load -i "/opt/docker-cache/<< parameters.img_name >>.docker"

  setup:
    description: "These steps should be run before any real ci/cd actions"
    steps:
      # add an ssh key granted with this circleci's settings for this repo
      - add_ssh_keys:
          fingerprints:
            - "7d:f1:8e:9e:99:9a:26:e2:4d:0c:66:f3:d4:74:10:e7"
      - setup_remote_docker:
          version: default
          docker_layer_caching: false
      - run:
          name: Common setup
          command: |
            #            ssh remote-docker \<<EOF
            #              sudo bash -c 'echo "{\"experimental\": true}" > /etc/docker/daemon.json'
            #              sudo systemctl restart docker
            #            EOF

            # AWS ECR Login, used by enough jobs to make it worthwhile for every job.
            # JSG update this to use "get-login-password" on new versions of aws cli
            whoami; pwd; ls -l /home
            eval $(aws ecr get-login --no-include-email --region ${ECR_REGION})
            # eval $(aws ecr get-login-password | docker login --username AWS --password-stdin ${AWS_ACCOUNT}.dkr.ecr.${ECR_REGION}.amazonaws.com)

            ssh-keygen -R github.com
            curl -L https://api.github.com/meta | jq -r '.ssh_keys | .[]' | sed -e 's/^/github.com /' >> ~/.ssh/known_hosts

            # Clone the commands repo, used by enough jobs to make it worthwhile for every job.
            if [ -n "$CIRCLE_BRANCH" ]; then
              echo "CIRCLE_BRANCH = $CIRCLE_BRANCH"
              COMMANDS_BRANCH_OR_TAG="$CIRCLE_BRANCH"
            else
              echo "CIRCLE_TAG = $CIRCLE_TAG"
              COMMANDS_BRANCH_OR_TAG="$CIRCLE_TAG"
            fi
            #git clone $CIRCLE_REPOSITORY_URL -b "$COMMANDS_BRANCH_OR_TAG" /home/ubuntu/commands

            #cd /home/ubuntu/commands
            #SHA=$(git rev-parse --short $CIRCLE_SHA1)

            # Save these off so jobs don't have to deduce them again.
            echo "$SHA" > /root/sha.txt
            #echo "$COMMANDS_BRANCH_OR_TAG" > /home/ubuntu/commands_branch_or_tag.txt

  setup_ecs_and_identities:
    description: |
      Downloads ecs, configures it and downloads node identities.
      This should be run before any deploy steps.
    steps:
      - run:
          name: Download ecs-cli and node identities
          command: |
            # download ecs cli
            curl -o /usr/local/bin/ecs-cli https://s3.amazonaws.com/amazon-ecs-cli/ecs-cli-linux-amd64-latest && \
            chmod +x /usr/local/bin/ecs-cli

            # configure ecs
            ecs-cli configure profile --access-key "$AWS_ACCESS_KEY_ID" --secret-key "$AWS_SECRET_ACCESS_KEY" --profile-name default
            ecs-cli configure --cluster "$CLUSTER_NAME" --region "$ECS_REGION" --config-name "$CLUSTER_NAME"

            # Download node identities
            S3_NODE_ID_ARCHIVE="node-identities-${NETWORK_NAME}.tgz"
            AWS_ACCESS_KEY_ID=$AWS_DEPLOY_SECRETS_ID \
            AWS_SECRET_ACCESS_KEY=$AWS_DEPLOY_SECRETS_KEY \
              aws s3 cp "s3://ndau-deploy-secrets/$S3_NODE_ID_ARCHIVE" "./$S3_NODE_ID_ARCHIVE"
            mkdir -p /root/node-identities
            tar xzvf "./$S3_NODE_ID_ARCHIVE" -C /root/node-identities

  deploy-net:
    description: Deploy using ECS
    steps:
      - setup
      - setup_ecs_and_identities
      - mark_honeycomb:
          msg: Start deploy for build $CIRCLE_BUILD_NUM
      - ecs_deploy
      - notify:
          msg: Deploy complete; nodes for $NETWORK_NAME are now running and healthy.

  ecs_deploy:
    description: Deploy using ECS
    steps:
      - run:
          name: Deploy to devnet
          command: |
            # If we're running a tagged build for deploying with reset data,
            # point it to the network's genesis snapshot.
            # Otherwise, take a snapshot before deploying and no data will be lost.
            if [ "$NETWORK_NAME" == "devnet" ]; then
                if [[ "$CIRCLE_TAG" == *"-jobs_"*"reset"* ]]; then
                    # We have a very specific and known devnet genesis snapshot (at height 27).
                    # If we ever regenerate it (which is currently a manual process), and it winds
                    # up with a different height postfix, we'll need to update this to match.
                    echo "Resetting devnet to genesis..."
                    echo "snapshot-devnet-27" > /root/latest-devnet.txt
                    aws s3 cp /root/latest-devnet.txt s3://ndau-snapshots/latest-devnet.txt
                else
                    # Take a snapshot before we deploy, so we don't lose any data.
                    # snapshot_node.py looks for the pem file in ~/.ssh, which is /root in Circle.
                    pem=/root/.ssh/sc-node-ec2.pem
                    echo "$SC_NODE_EC2_PEM" | base64 -d > "$pem"
                    chmod 600 "$pem"

                    if /home/ubuntu/commands/automation/snapshot_node.py devnet-4; then
                        echo "Snapshot taken on devnet-4"
                    else
                        # The deploy will just use whatever was in the last snapshot.
                        echo "Unable to take snapshot on devnet-4; deploy might lose data"
                    fi

                    rm -f "$pem"
                fi
            fi

            pids=()
            export SHA=$(cat /root/sha.txt)
            for i in $( seq 0 9 ); do # automatically deploy up to 10 nodes
              if [ -f  "/root/node-identities/node-identity-$i.tgz" ]; then
                echo "Found node identity at: /root/node-identities/node-identity-$i.tgz"
                /home/ubuntu/commands/deploy/deploy-node.sh $i $NETWORK_NAME /root/node-identities &
                pid="$!"
                pids=("${pids[@]}" "$pid")
                echo "Deploying $NETWORK_NAME-$i on pid $pid"
              fi # no else break in case some nodes are updated and others are not
            done

            # This will wait for all backgrounded deploy-node processes to complete.
            # It will fail and exit the overall deploy job if any one of them failed.
            for pid in "${pids[@]}"; do
                if ! wait "$pid"; then
                    echo "Deploy failed on pid $pid"
                    false
                fi
            done

            echo "Deploy of $NETWORK_NAME is complete"

workflows:
  version: 2
  master-build:
    jobs:
      - build:
          filters:
            branches:
              only: /^master$/
       # EJM Catchup now takes too long       
#      - catchup:
#          requires:
#            - build
#      - integration:
#          requires:
#            - build
      - push:
          requires:
            # Unlike tagged builds, master builds wait for tests to pass before pushing.
            # JSG don't require catchup here, takes too long, move down to deploy
            # - catchup
            # Suspend dependency on integration tests until they're fixed.
            # - integration
            - build
      - deploy:
          requires:
            # As above, catchup now takes several days - we can't wait
            # - catchup
            - push
  tagged-build:
    jobs:
      - build:
          filters:
            tags:
              # This causes circle to run this job on tagged non-master builds.
              only: /.*/
            branches:
              ignore: /^master$/
      # EJM - Avoid catchup: takes too long 
#      - catchup:
#          requires:
#            - build
#          filters:
#            tags:
#              only: /.*-jobs_.*?(catchup).*/
#            branches:
#              # This causes circle to skip this job on untagged non-master builds.
#              ignore: /.*/
#      - integration:
#          requires:
#            - build
#          filters:
#            tags:
#              only: /.*-jobs_.*?(push|integration).*/
#            branches:
#              # This causes circle to skip this job on untagged non-master builds.
#              ignore: /.*/
      - push:
          requires:
          - build
#            - integration
          filters:
            tags:
              only: /.*-jobs_.*?(push|deploy|reset).*/
            branches:
              # This causes circle to skip this job on untagged non-master builds.
              ignore: /.*/
      - deploy:
          requires:
            - push
          filters:
            tags:
              only: /.*-jobs_.*?(deploy|reset).*/

general_config: &general_config
    working_directory: /home/circleci/commands
    docker:
       - image: cimg/base:2024.06
#        - image: 578681496768.dkr.ecr.us-east-1.amazonaws.com/circle-ci:0.0.14
    environment:
        shell: /bin/bash
        <<: *aws_defaults
        NETWORK_NAME: devnet
        PERSISTENT_PEERS: 88cf98107823c1ca6621a0656daeecf731870532@devnet.ndau.tech:26660,7c7a66648ca0bf152aeee0c2d358f2d9f7b18341@devnet.ndau.tech:26661,dfa5eca4f826e977379e44d19dd606c06d8f7b7c@devnet.ndau.tech:26662,595562bf12ae2ba03d522f7026d9aa653ab9707c@devnet.ndau.tech:26663,59ed8217b8ef647b7ed1439408f3de35873e65d0@devnet.ndau.tech:26664 # devnet
        CLUSTER_NAME: devnet

jobs:
  # The stub jobs are useful to test workflows and their job filters on the circle server
  # without having to wait for actual work done by the jobs themselves.  The beef.js script
  # can also help with this, but it sometimes doesn't match what circle actually does.
  build-stub:
    <<: *general_config
    steps:
      - run:
          name: build stub
          command: |
            echo "build stub"
  catchup-stub:
    <<: *general_config
    steps:
      - run:
          name: catchup stub
          command: |
            echo "catchup stub"
  push-stub:
    <<: *general_config
    steps:
      - run:
          name: push stub
          command: |
            echo "push stub"
  deploy-stub:
    <<: *general_config
    steps:
      - run:
          name: deploy stub
          command: |
            echo "deploy stub"
  integration-stub:
    <<: *general_config
    steps:
      - run:
          name: integration stub
          command: |
            echo "integration stub"

  build:
    <<: *general_config
    steps:
      - setup
      - run:
          name: Build ndauimage
          command: |
            COMMANDS_BRANCH_OR_TAG=$(cat /home/ubuntu/commands_branch_or_tag.txt)

            # Create the machine_user_key file for buildimage.sh to use.
            echo -e "$machine_user_key" > /home/ubuntu/commands/machine_user_key

            # Run unit tests at build-time.  The Go code exists at that point and this saves us
            # from having an extra job when "build" and "test" are generally done concurrently,
            # and both are required to pass.  There is no case where we want one w/o the other.
            RUN_UNIT_TESTS=1 /home/ubuntu/commands/docker/bin/buildimage.sh "$COMMANDS_BRANCH_OR_TAG"
      - save_image:
          img_name: ndauimage:latest
          key: "{{ .Revision }}-ndauimage"

  catchup:
    <<: *general_config
    steps:
      - setup
      - restore_image:
          img_name: ndauimage:latest
          key: "{{ .Revision }}-ndauimage"
      - run:
          name: Test catchup on mainnet from genesis
          command: |
            # Run a local node connected to mainnet starting from the genesis snapshot.
            nodename="catchup-node"
            # JSG run from recent snapshot, limiting runtime for CI
            snapshot="snapshot-mainnet-497500"
            USE_LOCAL_IMAGE=1 \
            AWS_ACCESS_KEY_ID="" \
            AWS_SECRET_ACCESS_KEY="" \
            SLACK_DEPLOYS_KEY="" \
              /home/ubuntu/commands/docker/bin/runcontainer.sh mainnet "$nodename" 26660 26670 3030 \
                "" "$snapshot"

            echo

            # Get the current height of mainnet.  We need to catch up to at least this height.
            # Use mainnet-2 since that's in the same region as devnet, our deploy target.
            status=$(curl -s https://mainnet-2.ndau.tech:26670/status)
            height=$(echo $status | sed -n -e 's/.*latest_block_height....\([0-9]\{1,\}\).*/\1/p')
            if [ -z "$height" ] || [ $height -le 0 ]; then
              echo "Unable to get mainnet height"
              false
            fi
            echo "Current mainnet height: $height"

            # Catching up on mainnet will take longer and longer as the block height of mainnet
            # increases over time.  This is known and we'll need to deal with it at some point.
            # https://github.com/ndau/commands/issues/354
            printf "Catching up..."
            last_h=0
            while : ; do
              sleep 10
              if ! s=$(docker exec "$nodename" curl -s http://localhost:26670/status); then
                # The status query is what usually fails when playback of a block fails.
                printf " (ERROR: unable to catch up)"
                break
              fi

              h=$(echo $s | sed -n -e 's/.*latest_block_height....\([0-9]\{1,\}\).*/\1/p')
              if [ -z "$h" ]; then
                # If we didn't get a height back, something went wrong; assume failed catchup.
                printf " (ERROR: no height)"
                break
              fi
              printf " $h\n"

              catching_up=$(echo $s | sed -n -e 's/.*catching_up...\([a-z]\{1,\}\).*/\1/p')
              if [ "$catching_up" = "false" ] && [ $h -ge $height ]; then
                caught_up=1
                printf " (caught up)"
                break
              fi

              if [ $h -le $last_h ]; then
                # Fail if we didn't catch up at all since the last iteration.
                # This indicates a stall, which likely means we're failing on full catchup.
                printf " (ERROR: stalled)"
                # JSG don't break here, just print message and try to keep going, usually this is not a fatal error
                # break
              fi

              last_h=$h
            done
            printf "\n"

            echo

            # Stop and remove the container instance for the catchup test node.
            /home/ubuntu/commands/docker/bin/removecontainer.sh "$nodename"

            echo

            if [ -z "$caught_up" ]; then
              echo "Catchup failed"
              false
            fi

            echo "Catchup complete"

  push:
    <<: *general_config
    steps:
      - setup
      - restore_image:
          img_name: ndauimage:latest
          key: "{{ .Revision }}-ndauimage"
      - run:
          name: Push ndauimage to ECR
          command: |
            SHA=$(cat /root/sha.txt)
            # upload the image to S3 for public access
            docker tag ndauimage ndauimage:$SHA
            docker save ndauimage:$SHA -o /root/ndauimage-$SHA.docker
            gzip -f /root/ndauimage-$SHA.docker
            aws s3 cp /root/ndauimage-$SHA.docker.gz s3://ndau-images/ndauimage-$SHA.docker.gz
            # update the current-*.txt file for the network we're deploying to
            # but only if we're deploying to master (e.g. don't do this for tagged pushes)
            if [ "$CIRCLE_BRANCH" = "master" ]; then
                echo $SHA > /root/current-$NETWORK_NAME.txt
                aws s3 cp /root/current-$NETWORK_NAME.txt \
                    s3://ndau-images/current-$NETWORK_NAME.txt
            fi
            # retag built image
            docker tag ndauimage $AWS_ACCOUNT.dkr.ecr.$ECR_REGION.amazonaws.com/ndauimage:$SHA
            docker rmi ndauimage:$SHA
            # push the image to ECR
            docker push $AWS_ACCOUNT.dkr.ecr.$ECR_REGION.amazonaws.com/ndauimage:$SHA

  deploy:
    <<: *general_config
    steps:
      - deploy-net

  integration:
    <<: *general_config
    steps:
      - setup
      - restore_image:
          img_name: ndauimage:latest
          key: "{{ .Revision }}-ndauimage"
      - run:
          name: Run integration tests
          command: |
            # In order to get two node containers talking to each other, and to get integration
            # tests talking to them, they must each be in their own child containers within the
            # docker "bridge" network.  Each node is in its own container automatically, then we
            # spin up a child ndauimage container from which integration tests will run.

            # Run two local nodes.
            # Integration tests only require one, but running two exercises p2p operations.
            echo "Starting first node..."
            bin_dir="/commands/docker/bin"
            # Using "*" will cause the node to generate single validator genesis data.
            AWS_ACCESS_KEY_ID="" \
            AWS_SECRET_ACCESS_KEY="" \
            SLACK_DEPLOYS_KEY="" \
            TM_LOG_LEVEL="*:info" \
            PEX=true \
            SEED_MODE=false \
              "$bin_dir"/runcontainer.sh localnet localnet-0 26660 26670 3030 "" "*"

            # Get the ip of the first node.
            ip=$(docker container inspect localnet-0 | \
                 jq -r .[0].NetworkSettings.Networks.bridge.IPAddress)
            echo "localnet-0 ip: $ip"

            # Get the peer id of the first node.
            id=$(docker exec localnet-0 curl -s http://localhost:26670/status | \
                 jq -r .result.node_info.id)
            echo "localnet-0 id: $id"

            # Generate the snapshot.
            echo "Taking genesis snapshot..."
            "$bin_dir"/snapshotcontainer.sh localnet-0

            # Start the second container.  We can't use runcontainer.sh here because it tests
            # port connectivity with peers, and localnet-0's IP isn't valid ouside of containers
            # on the bridge network.  So we implement the meat of runcontainer.sh here:
            echo "Starting second node..."
            docker create \
              --name localnet-1 \
              -e NETWORK=localnet \
              -e HONEYCOMB_DATASET="$HONEYCOMB_DATASET" \
              -e HONEYCOMB_KEY="$HONEYCOMB_KEY" \
              -e AWS_ACCESS_KEY_ID="" \
              -e AWS_SECRET_ACCESS_KEY="" \
              -e SLACK_DEPLOYS_KEY="" \
              -e NODE_ID=localnet-1 \
              -e PERSISTENT_PEERS="$id@$ip:26660" \
              -e PEX=true \
              -e TM_LOG_LEVEL="*:info" \
              -e SEED_MODE=false \
              ndauimage
            # The ndauimage container looks for a specially-named snapshot ending with "-0".
            docker cp "$bin_dir"/snapshot-localnet-1.tgz localnet-1:/image/snapshot-localnet-0.tgz
            docker start localnet-1
            echo "Waiting for localnet-1 to fully spin up..."
            until docker exec localnet-1 test -f /image/running 2>/dev/null
            do
                sleep 1
            done
            echo "localnet-1 is ready; dumping container logs..."
            docker container logs localnet-1 2>/dev/null | sed -e 's/^/> /'
            # --- end of code adapted from runcontainer.sh ---

            # Integration tests do not require a multi-node network, but we'd like to ensure that
            # exercising p2p features at least.  Make sure both nodes have each other as peers.
            echo "Checking peers..."
            for i in {0..1}; do
              num_peers=$(docker exec localnet-$i curl -s http://localhost:26670/net_info | \
                 jq -r .result.n_peers)
              if [ "$num_peers" != "1" ]; then
                echo "ERROR: localnet-$i expected to have 1 peer but has $num_peers"
                false
              fi
            done

            # Pull down a copy of integration-tests repo.  We'll copy it into the tests container.
            echo "Cloning integration-tests..."
            git clone git@github.com:ndau/integration-tests.git /integration-tests
            cd /integration-tests
            echo "integration-tests repo at $(git rev-parse --short HEAD)"

            # Create a container that integration tests can run out of.  Use the ndauimage.
            echo "Creating tests container..."
            container=tests-container
            docker create \
                --name "$container" \
                --entrypoint "/root/integration.sh" \
                -e "IP=$ip" \
                ndauimage
            docker cp /home/ubuntu/commands/deploy/integration.sh "$container":/root/integration.sh
            docker cp localnet-0:/image/system_accounts.toml /system_accounts.toml
            docker cp /system_accounts.toml "$container":/system_accounts.toml
            docker cp localnet-0:/image/data/tendermint/config/priv_validator_key.json \
                      /priv_validator_key.json
            docker cp /priv_validator_key.json "$container":/priv_validator_key.json
            docker cp /integration-tests "$container":/integration-tests

            # Run the tests.
            echo "Running tests..."
            docker start "$container"

            # Dump this in case it's useful for debugging container problems later.
            echo "Inspecting bridge network..."
            docker network inspect bridge

            # This serves as a "docker wait" that dumps integration-tests output to circle.
            docker container logs --follow "$container"

            # Fail the circle job if the container exited with a non-zero exit code.
            exitcode=$(docker inspect $container --format={{.State.ExitCode}})
            if [ "$exitcode" != "0" ]; then
              echo "Integration failed ($exitcode)"
              false
            fi

            echo "Integration complete"
